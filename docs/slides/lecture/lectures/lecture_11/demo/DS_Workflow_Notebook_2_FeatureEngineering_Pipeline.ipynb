{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18b8b67",
   "metadata": {},
   "source": [
    "\n",
    "# The End-to-End Data Science Workflow ‚Äî Notebook 2/4\n",
    "## Feature Engineering & Preprocessing Pipeline üõ†Ô∏è\n",
    "\n",
    "**Goal.** Engineer features, handle heterogeneous data, and build a leak-proof preprocessing pipeline using `scikit-learn` primitives.\n",
    "\n",
    "**Libraries used (with roles):**\n",
    "- `numpy`, `pandas`: data wrangling and deterministic behavior.\n",
    "- `scikit-learn`: `Pipeline`, `ColumnTransformer`, `SimpleImputer`, `StandardScaler`,\n",
    "  `OneHotEncoder`, `OrdinalEncoder`, `train_test_split`.\n",
    "- `joblib`: persist fitted preprocessors/artifacts.\n",
    "- `matplotlib`: quick diagnostic plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa9ef1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====== Imports, Paths, Seed ======\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib\n",
    "\n",
    "RANDOM_SEED = 42; np.random.seed(RANDOM_SEED)\n",
    "DATA_DIR = Path(\"data\"); ARTIFACTS_DIR = Path(\"artifacts\")\n",
    "DATA_DIR.mkdir(exist_ok=True); ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "CLEAN_DATA_PATH = DATA_DIR / \"loan_default_clean_base.csv\"\n",
    "PREPROCESSOR_PATH = ARTIFACTS_DIR / \"preprocessor.joblib\"\n",
    "FEATURE_NAMES_PATH = ARTIFACTS_DIR / \"feature_names.csv\"\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 4.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c44509b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4800, 15)  Test: (1200, 15)  Pos rate train: 0.103\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====== Load Data & Split BEFORE Any Fitting ======\n",
    "if CLEAN_DATA_PATH.exists():\n",
    "    df = pd.read_csv(CLEAN_DATA_PATH, parse_dates=[\"application_date\"])\n",
    "else:\n",
    "    raise FileNotFoundError(\"Expected base dataset not found. Run Notebook 1 first (or ensure the CSV exists).\")\n",
    "\n",
    "y = df[\"default\"].astype(int)\n",
    "X = df.drop(columns=[\"default\"])\n",
    "\n",
    "# CRITICAL: Split first to avoid leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape, \" Pos rate train:\", y_train.mean().round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5198ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====== Feature Engineering Transformer ======\n",
    "# BEST PRACTICE: Place all transformations inside sklearn-compatible components.\n",
    "class FeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, clip_dti=10.0, rare_cutoff=0.01):\n",
    "        self.clip_dti = clip_dti\n",
    "        self.rare_cutoff = rare_cutoff\n",
    "        self.rare_maps_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Identify rare categories per column (on TRAIN only)\n",
    "        cat_cols = [\"state\",\"home_ownership\",\"purpose\",\"applicant_gender\"]\n",
    "        self.rare_maps_ = {}\n",
    "        for c in cat_cols:\n",
    "            vc = X[c].value_counts(normalize=True, dropna=False)\n",
    "            rare = set(vc[vc < self.rare_cutoff].index.tolist())\n",
    "            if len(rare) > 0:\n",
    "                self.rare_maps_[c] = rare\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        # Debt-to-income\n",
    "        X_[\"dti\"] = (X_[\"total_debt\"] / X_[\"income\"]).replace([np.inf,-np.inf], np.nan)\n",
    "        X_[\"dti\"] = X_[\"dti\"].clip(0, self.clip_dti)\n",
    "\n",
    "        # Date-derived\n",
    "        X_[\"app_month\"] = X_[\"application_date\"].dt.month\n",
    "        X_[\"app_dayofweek\"] = X_[\"application_date\"].dt.dayofweek\n",
    "        X_[\"app_year\"] = X_[\"application_date\"].dt.year\n",
    "\n",
    "        # Interaction terms\n",
    "        X_[\"rate_term_interaction\"] = X_[\"interest_rate\"] * X_[\"term_months\"]\n",
    "        X_[\"amount_income_ratio\"] = X_[\"loan_amount\"] / np.maximum(X_[\"income\"], 1.0)\n",
    "\n",
    "        # Rare-category bucketing to reduce dimensionality\n",
    "        for c, rare_set in self.rare_maps_.items():\n",
    "            X_[c] = X_[c].astype(\"object\")\n",
    "            X_.loc[X_[c].isin(rare_set), c] = \"__RARE__\"\n",
    "            X_[c] = X_[c].astype(\"category\")\n",
    "        return X_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69223a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====== Column Definitions ======\n",
    "ordinal_edu = [\"High School\",\"Bachelor\",\"Master\",\"PhD\"]\n",
    "numeric_features = [\n",
    "    \"age\",\"income\",\"loan_amount\",\"term_months\",\"interest_rate\",\"credit_score\",\"employment_years\",\"total_debt\",\n",
    "    \"dti\",\"app_month\",\"app_dayofweek\",\"app_year\",\"rate_term_interaction\",\"amount_income_ratio\"\n",
    "]\n",
    "categorical_nominal = [\"state\",\"home_ownership\",\"purpose\",\"applicant_gender\"]\n",
    "categorical_ordinal = [\"education_level\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aa566ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====== ColumnTransformer with Robust Defaults ======\n",
    "num_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")), (\"sc\", StandardScaler())])\n",
    "ord_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")), (\"ord\", OrdinalEncoder(categories=[ordinal_edu], dtype=float))])\n",
    "nom_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")), (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))])\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", num_pipe, numeric_features),\n",
    "    (\"ord\", ord_pipe, categorical_ordinal),\n",
    "    (\"nom\", nom_pipe, categorical_nominal)\n",
    "], remainder=\"drop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56a11f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed (train,test): (4800, 36) (1200, 36)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====== Full Preprocessor Pipeline ======\n",
    "preprocess = Pipeline([(\"feat\", FeatureGenerator(clip_dti=10.0, rare_cutoff=0.01)), (\"pre\", pre)])\n",
    "\n",
    "# Fit on TRAIN ONLY\n",
    "Xtr = preprocess.fit_transform(X_train, y_train)\n",
    "Xte = preprocess.transform(X_test)\n",
    "print(\"Transformed (train,test):\", Xtr.shape, Xte.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e6df8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total feature count: 36\n",
      "Sample of names: ['age', 'income', 'loan_amount', 'term_months', 'interest_rate', 'credit_score', 'employment_years', 'total_debt', 'dti', 'app_month', 'app_dayofweek', 'app_year', 'rate_term_interaction', 'amount_income_ratio', 'education_level', 'state__S01', 'state__S02', 'state__S03', 'state__S04', 'state__S05']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====== Introspect Feature Names ======\n",
    "def feature_names_from_preprocessor(preprocess_pipeline):\n",
    "    pre = preprocess_pipeline.named_steps[\"pre\"]\n",
    "    ohe = pre.named_transformers_[\"nom\"].named_steps[\"ohe\"]\n",
    "    # OHE names with categories\n",
    "    ohe_names = []\n",
    "    for col, cats in zip([\"state\",\"home_ownership\",\"purpose\",\"applicant_gender\"], ohe.categories_):\n",
    "        for c in cats:\n",
    "            ohe_names.append(f\"{col}__{c}\")\n",
    "    names = list(numeric_features) + [\"education_level\"] + ohe_names\n",
    "    return names\n",
    "\n",
    "feat_names = feature_names_from_preprocessor(preprocess)\n",
    "print(\"Total feature count:\", len(feat_names))\n",
    "print(\"Sample of names:\", feat_names[:20])\n",
    "\n",
    "# Save for downstream inspection\n",
    "pd.Series(feat_names, name=\"feature_name\").to_csv(FEATURE_NAMES_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32f83cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessor to: artifacts/preprocessor.joblib\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====== Save Preprocessor Artifact ======\n",
    "joblib.dump(preprocess, PREPROCESSOR_PATH)\n",
    "print(\"Saved preprocessor to:\", PREPROCESSOR_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a6802e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means ~ 0: [ 0. -0. -0. -0.]\n",
      "Stds ~ 1: [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====== Sanity Plot: Standardized Numeric Preview ======\n",
    "# Quick check that scaling worked (mean‚âà0, std‚âà1) for a few numeric features.\n",
    "import numpy as np\n",
    "std_preview_cols = [\"age\",\"income\",\"loan_amount\",\"interest_rate\"]\n",
    "idx = [numeric_features.index(c) for c in std_preview_cols]\n",
    "arr = Xtr[:, idx]\n",
    "print(\"Means ~ 0:\", np.round(arr.mean(axis=0), 3))\n",
    "print(\"Stds ~ 1:\", np.round(arr.std(axis=0), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ed0e2-5671-46f2-a4f8-089759bf73a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
